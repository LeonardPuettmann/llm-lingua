{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 1.73k/1.73k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|██████████| 94.1M/94.1M [00:17<00:00, 5.25MB/s]\n",
      "Generating train split: 100%|██████████| 313342/313342 [00:01<00:00, 171375.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mik3ml/italian-dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                         definition  \\\n",
      "0            1  \\n### Sostantivo\\n\\n\\nabaca ( approfondimento)...   \n",
      "1            2  \\n###  Sostantivo, forma flessa\\n\\n\\nabachi m ...   \n",
      "2            3  \\n### Sostantivo\\n\\n\\nabachista m e f (pl.: ab...   \n",
      "3            4  \\n###  Sostantivo, forma flessa\\n\\n\\nabachisti...   \n",
      "4            5  \\n### Sostantivo\\n\\n\\nabaco m sing (pl.: abach...   \n",
      "...        ...                                                ...   \n",
      "313337  313338  \\n### Sostantivo\\n\\n\\nzuzzurullone m sing, f p...   \n",
      "313338  313339  \\n###  Sostantivo, forma flessa\\n\\n\\nzuzzurull...   \n",
      "313339  313340  \\n### Sostantivo\\n\\n\\nzwinglismo ( approfondim...   \n",
      "313340  313341  \\n### Aggettivo\\n\\n\\nzwinglista o zuinglista m...   \n",
      "313341  313342  \\n### Interiezione\\n\\n\\nzzz\\n\\n\\n- (onomatopei...   \n",
      "\n",
      "                word covered learned  \n",
      "0              abaca      no      no  \n",
      "1             abachi      no      no  \n",
      "2          abachista      no      no  \n",
      "3          abachisti      no      no  \n",
      "4              abaco      no      no  \n",
      "...              ...     ...     ...  \n",
      "313337  zuzzurullone      no      no  \n",
      "313338  zuzzurulloni      no      no  \n",
      "313339    zwinglismo      no      no  \n",
      "313340    zwinglista      no      no  \n",
      "313341           zzz      no      no  \n",
      "\n",
      "[313342 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('./database/vocabulary.db')\n",
    "\n",
    "# Add the new columns \"covered\" and \"learned\" to your DataFrame\n",
    "df['covered'] = 'no'\n",
    "df['learned'] = 'no'\n",
    "\n",
    "# Write your DataFrame to the SQLite database\n",
    "df.to_sql('dictionary', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Reopen the connection, create a cursor, and execute a query to retrieve the data\n",
    "conn = sqlite3.connect('./database/vocabulary.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM dictionary\")\n",
    "result = cursor.fetchall()\n",
    "conn.close()\n",
    "\n",
    "# Convert the result to a new DataFrame\n",
    "df_result = pd.DataFrame(result, columns=[column[0] for column in cursor.description])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    conn = None;\n",
    "    try:\n",
    "        conn = sqlite3.connect('./database/vocabulary.db')\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    "    return conn\n",
    "\n",
    "conn = create_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_words(input_string, conn):\n",
    "    # Tokenize the input string into words\n",
    "    words = set(input_string.split(\" \"))\n",
    "\n",
    "    # Create a cursor and execute a query to retrieve the words from the database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT word FROM dictionary\")\n",
    "    db_words = set([row[0] for row in cursor])\n",
    "\n",
    "    # Find the intersection of the input words and the database words\n",
    "    italian_words = words & db_words\n",
    "\n",
    "    # Update the 'covered' column for the matching words\n",
    "    for word in italian_words:\n",
    "        if len(word) >= 3:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piace\n"
     ]
    }
   ],
   "source": [
    "check_words(\"My favourite word is piace\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
